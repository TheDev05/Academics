{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Project : Calorie and Food estimation using ML and DL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T15:45:30.580746Z","iopub.execute_input":"2023-10-01T15:45:30.581208Z","iopub.status.idle":"2023-10-01T15:45:30.735067Z","shell.execute_reply.started":"2023-10-01T15:45:30.581174Z","shell.execute_reply":"2023-10-01T15:45:30.734236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:44.559910Z","iopub.execute_input":"2023-10-01T15:45:44.560289Z","iopub.status.idle":"2023-10-01T15:45:44.566134Z","shell.execute_reply.started":"2023-10-01T15:45:44.560262Z","shell.execute_reply":"2023-10-01T15:45:44.565371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list with the filepaths for training and testing\ntrain_dir = Path('../input/fruit-and-vegetable-image-recognition/train')\ntrain_filepaths = list(train_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:46.753735Z","iopub.execute_input":"2023-10-01T15:45:46.754131Z","iopub.status.idle":"2023-10-01T15:45:46.825300Z","shell.execute_reply.started":"2023-10-01T15:45:46.754098Z","shell.execute_reply":"2023-10-01T15:45:46.824181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = Path('../input/fruit-and-vegetable-image-recognition/test')\ntest_filepaths = list(test_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:49.481916Z","iopub.execute_input":"2023-10-01T15:45:49.482283Z","iopub.status.idle":"2023-10-01T15:45:49.524302Z","shell.execute_reply.started":"2023-10-01T15:45:49.482255Z","shell.execute_reply":"2023-10-01T15:45:49.523187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dir = Path('../input/fruit-and-vegetable-image-recognition/validation')\nval_filepaths = list(test_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:51.634166Z","iopub.execute_input":"2023-10-01T15:45:51.634547Z","iopub.status.idle":"2023-10-01T15:45:51.681303Z","shell.execute_reply.started":"2023-10-01T15:45:51.634518Z","shell.execute_reply":"2023-10-01T15:45:51.680341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_processing(filepath):\n    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n\n    labels = [str(filepath[i]).split(\"/\")[-2] \\\n              for i in range(len(filepath))]\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:53.838029Z","iopub.execute_input":"2023-10-01T15:45:53.838578Z","iopub.status.idle":"2023-10-01T15:45:53.843873Z","shell.execute_reply.started":"2023-10-01T15:45:53.838550Z","shell.execute_reply":"2023-10-01T15:45:53.842910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = image_processing(train_filepaths)\ntest_df = image_processing(test_filepaths)\nval_df = image_processing(val_filepaths)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:56.671356Z","iopub.execute_input":"2023-10-01T15:45:56.671886Z","iopub.status.idle":"2023-10-01T15:45:56.699083Z","shell.execute_reply.started":"2023-10-01T15:45:56.671843Z","shell.execute_reply":"2023-10-01T15:45:56.698024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('-- Training set --\\n')\nprint(f'Number of pictures: {train_df.shape[0]}\\n')\nprint(f'Number of different labels: {len(train_df.Label.unique())}\\n')\nprint(f'Labels: {train_df.Label.unique()}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:45:59.602939Z","iopub.execute_input":"2023-10-01T15:45:59.603315Z","iopub.status.idle":"2023-10-01T15:45:59.610128Z","shell.execute_reply.started":"2023-10-01T15:45:59.603278Z","shell.execute_reply":"2023-10-01T15:45:59.608921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:46:02.744996Z","iopub.execute_input":"2023-10-01T15:46:02.745371Z","iopub.status.idle":"2023-10-01T15:46:02.753637Z","shell.execute_reply.started":"2023-10-01T15:46:02.745344Z","shell.execute_reply":"2023-10-01T15:46:02.752918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with one Label of each category\ndf_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display some pictures of the dataset\nfig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i], fontsize = 12)\nplt.tight_layout(pad=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:46:05.429135Z","iopub.execute_input":"2023-10-01T15:46:05.429772Z","iopub.status.idle":"2023-10-01T15:46:14.686993Z","shell.execute_reply.started":"2023-10-01T15:46:05.429728Z","shell.execute_reply":"2023-10-01T15:46:14.685934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:46:20.461014Z","iopub.execute_input":"2023-10-01T15:46:20.461436Z","iopub.status.idle":"2023-10-01T15:46:20.468221Z","shell.execute_reply.started":"2023-10-01T15:46:20.461395Z","shell.execute_reply":"2023-10-01T15:46:20.466917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:46:23.738691Z","iopub.execute_input":"2023-10-01T15:46:23.739080Z","iopub.status.idle":"2023-10-01T15:46:24.976087Z","shell.execute_reply.started":"2023-10-01T15:46:23.739051Z","shell.execute_reply":"2023-10-01T15:46:24.975184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images = train_generator.flow_from_dataframe(\n    dataframe=val_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:46:27.639259Z","iopub.execute_input":"2023-10-01T15:46:27.639610Z","iopub.status.idle":"2023-10-01T15:46:27.797655Z","shell.execute_reply.started":"2023-10-01T15:46:27.639577Z","shell.execute_reply":"2023-10-01T15:46:27.796902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:46:30.436320Z","iopub.execute_input":"2023-10-01T15:46:30.436694Z","iopub.status.idle":"2023-10-01T15:46:30.450925Z","shell.execute_reply.started":"2023-10-01T15:46:30.436662Z","shell.execute_reply":"2023-10-01T15:46:30.449913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:20:18.743306Z","iopub.execute_input":"2023-10-01T16:20:18.743650Z","iopub.status.idle":"2023-10-01T16:20:20.026306Z","shell.execute_reply.started":"2023-10-01T16:20:18.743623Z","shell.execute_reply":"2023-10-01T16:20:20.025239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(36, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=5,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=2,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:29:19.828044Z","iopub.execute_input":"2023-10-01T16:29:19.828437Z","iopub.status.idle":"2023-10-01T16:39:49.971813Z","shell.execute_reply.started":"2023-10-01T16:29:19.828400Z","shell.execute_reply":"2023-10-01T16:39:49.970916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred1 = [labels[k] for k in pred]\npred1","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:40:51.373473Z","iopub.execute_input":"2023-10-01T16:40:51.373903Z","iopub.status.idle":"2023-10-01T16:41:08.194579Z","shell.execute_reply.started":"2023-10-01T16:40:51.373871Z","shell.execute_reply":"2023-10-01T16:41:08.193489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def output(location):\n    img=load_img(location,target_size=(224,224,3))\n    img=img_to_array(img)\n    img=img/255\n    img=np.expand_dims(img,[0])\n    answer=model.predict(img)\n    y_class = answer.argmax(axis=-1)\n    y = \" \".join(str(x) for x in y_class)\n    y = int(y)\n    res = labels[y]\n    return res","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:18:42.254289Z","iopub.status.idle":"2023-10-01T16:18:42.255105Z","shell.execute_reply.started":"2023-10-01T16:18:42.254819Z","shell.execute_reply":"2023-10-01T16:18:42.254864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = output('/kaggle/input/inputs/Image_6.jpg')\nimg","metadata":{"execution":{"iopub.status.busy":"2023-10-01T17:27:55.612314Z","iopub.execute_input":"2023-10-01T17:27:55.612678Z","iopub.status.idle":"2023-10-01T17:27:55.749936Z","shell.execute_reply.started":"2023-10-01T17:27:55.612650Z","shell.execute_reply":"2023-10-01T17:27:55.748897Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 51ms/step\n","output_type":"stream"},{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"'garlic'"},"metadata":{}}]},{"cell_type":"code","source":"import requests\nimport json\n\napi_url = 'https://api.api-ninjas.com/v1/nutrition?query={}'.format(img)\nresponse = requests.get(api_url, headers={'X-Api-Key': 'FJCuuMBu83nEaI7CGroR8A==z88oB9CslsPk9p80'})\nif response.status_code == requests.codes.ok:\n    employee_string = response.text\n    json_object = json.loads(employee_string)\n    print(json.dumps(json_object[0], indent=4))\nelse:\n    print(\"Error:\", response.status_code, response.text)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T17:52:30.411696Z","iopub.execute_input":"2023-10-01T17:52:30.412953Z","iopub.status.idle":"2023-10-01T17:52:31.008926Z","shell.execute_reply.started":"2023-10-01T17:52:30.412905Z","shell.execute_reply":"2023-10-01T17:52:31.007745Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"{\n    \"name\": \"garlic\",\n    \"calories\": 144.8,\n    \"serving_size_g\": 100.0,\n    \"fat_total_g\": 0.7,\n    \"fat_saturated_g\": 0.0,\n    \"protein_g\": 6.4,\n    \"sodium_mg\": 16,\n    \"potassium_mg\": 153,\n    \"cholesterol_mg\": 0,\n    \"carbohydrates_total_g\": 32.5,\n    \"fiber_g\": 2.0,\n    \"sugar_g\": 1.0\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('FV.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:03.821194Z","iopub.execute_input":"2023-10-01T16:55:03.821923Z","iopub.status.idle":"2023-10-01T16:55:04.083479Z","shell.execute_reply.started":"2023-10-01T16:55:03.821884Z","shell.execute_reply":"2023-10-01T16:55:04.082731Z"},"trusted":true},"execution_count":null,"outputs":[]}]}